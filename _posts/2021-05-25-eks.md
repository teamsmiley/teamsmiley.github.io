---
layout: post
title: 'eks'
author: teamsmiley
date: 2021-05-25
tags: [devops]
image: /files/covers/blog.jpg
category: { kubernetes }
---

# aws eks (kubernetes) 사용하기

eks는 아마존에서 관리해주는 쿠버네티스이다. 마스터를 다 관리를 해주므로 사용하기만 해서 많이 편하다.

## prerequisite

- aws어카운트는 미리 만들어 두셔야 따라하실수 있습니다.
- 가능하면 로그인 하는 유저의 secret키를 만들어 두시면 좋을거같습니다. 아래쪽 스탭을 참고해주세요

## 랩탑에 관련 프로그램 설치

### kubectl

https://kubernetes.io/docs/tasks/tools/

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-09-21-21.png)

### k9s

https://k9scli.io/

https://k9scli.io/topics/install/

### aws cli 설치

```bash
curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"
sudo installer -pkg AWSCLIV2.pkg -target /
```

### AWS 액세스 키 생성

![]({{ site_baseurl }}/assets/2021-05-25-eks/2020-11-16-09-52-22.png)

### setup command line

```bash
aws configure
```

생성한 키와 내용을 넣는다.

~/.aws/에 파일이 생성된다. 내용 확인

```bash
cat ~/.aws/config
cat ~/.aws/credentials
```

### 기본 유저 설정

여러개의 프로파일일 경우 프로파일 이름을 설정한다.

```bash
export AWS_PROFILE=Profile_Name
```

확인

```bash
aws help
aws command help
aws command subcommand help
aws ec2 describe-instances help

aws ec2 describe-instances  --region us-west-2 --query "Reservations[].Instances[].InstanceId"
```

### eksctl 설치

https://eksctl.io

```bash
brew install aws-iam-authenticator
brew tap weaveworks/tap
brew install weaveworks/tap/eksctl
```

리눅스 윈도우 사용자는 <https://eksctl.io/introduction/#installation> 참고

### install Argo CD CLI

```bash
brew install argocd
```

## kubernetes cluster 생성

```bash
eksctl create cluster \
--name cluster-1 \
--version 1.18 \
--region us-west-2 \
--nodegroup-name c1-nodes \
--node-type t3.medium \
--nodes 2
```

- type
  - t3.nano
  - t3.micro
  - t3.small
  - t3.medium
  - t3.large

```bash
2021-05-10 12:22:19 [ℹ]  waiting for the control plane availability...
2021-05-10 12:22:19 [✔]  saved kubeconfig as "/Users/ragon/.kube/c2-config"
2021-05-10 12:22:19 [ℹ]  no tasks
2021-05-10 12:22:19 [✔]  all EKS cluster resources for "cluster01" have been created
2021-05-10 12:22:39 [ℹ]  adding identity "arn:aws:iam::849053568:role/eksctl-cluster01-nodegroup-cluste-NodeInstanceRole-PFUE0IKTPN8T" to auth ConfigMap
2021-05-10 12:22:40 [ℹ]  nodegroup "cluster01-nodes" has 0 node(s)
2021-05-10 12:22:40 [ℹ]  waiting for at least 4 node(s) to become ready in "cluster01-nodes"
```

## 생성 확인

```bash
eksctl get cluster
ls ~/.kube/
cat ~/.kube/config
```

생성이 되고 나면 ~/.kube/ 폴더에 config파일이 생성이 된다. 이 정보로 kubernetes와 통신할수 있다.

```yml
apiVersion: v1
clusters:
  - cluster:
      certificate-authority-data: xxxx
    name: cluster-1
contexts:
  - context:
      cluster: cluster-1
      user: cluster-1
    name: cluster-1
kind: Config
preferences: {}
users:
  - name: cluster-1
    user:
      exec:
        apiVersion: client.authentication.k8s.io/v1alpha1
        args:
          - token
          - -i
          - cluster01
        command: aws-iam-authenticator
        env:
          - name: AWS_STS_REGIONAL_ENDPOINTS
            value: regional
          - name: AWS_DEFAULT_REGION
            value: us-west-2
          - name: AWS_PROFILE
            value: Profile_Name
```

이부분을 주의하자 없으면 넣어줄것.

```yml
- name: AWS_PROFILE
  value: Profile_Name
```

## config를 이용한 생성

vi config.yml

```yml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: cluster-in-existing-vpc
  region: us-west-2

vpc:
  subnets:
    private:
      eu-north-1a: { id: subnet-0fxxx6e0c4a6d300c }
      eu-north-1b: { id: subnet-05xxxb573695c03 }
      eu-north-1c: { id: subnet-04xxxa607393184 }

nodeGroups:
  - name: ng-1-workers
    labels: { role: workers }
    instanceType: t3.micro
    desiredCapacity: 10
    privateNetworking: true
```

```bash
eksctl create cluster --config-file=./config.yml --kubeconfig ~/.kube/aws-config
```

## 접속 확인

vi ~/.zshrc

```bash
export KUBECONFIG=~/.kube/config
```

```bash
kubectl get node
```

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-09-28-48.png)

## check cluster

```bash
eksctl get cluster
```

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-08-35-03.png)

## argocd

### install

```bash
kubectl create namespace argocd
curl -o init/install_argocd.yaml https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

k apply -n argocd -f init/install_argocd.yaml
```

### git 생성

argocd는 git으로 모든걸 관리하기때문에 git repo를 하나 만들어보자. 저는 github을 사용.

핵심은 프로그램 소스가 들어 있는 git은 따로 있고 여기서 생성한 git은 쿠버네티를 관리하기 위한 새로운 git repo이다.

### install Argo CD CLI

```bash
brew install argocd
```

### 접속

```bash
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

<http://localhost:8080>

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-09-04.png)

### 비번 알아내기

```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d && echo

XXXXXXXXX
```

admin/XXXXXXXXX 로 접속하면 된다.

### cert-manager를 추가

argo ui에서 helm repo 등록 : https://charts.jetstack.io

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-10-16.png)

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-11-18.png)

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-12-16.png)

cert-manager 를 앱으로 등록하자.

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-13-08.png)

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-13-45.png)

```yml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cert-manager
  namespace: argocd
spec:
  destination:
    name: ''
    namespace: cert-manager
    server: 'https://kubernetes.default.svc'
  source:
    path: ''
    repoURL: 'https://charts.jetstack.io'
    targetRevision: v1.3.1
    chart: cert-manager
    helm:
      parameters:
        - name: installCRDs
          value: 'true'
  project: default
  syncPolicy:
    syncOptions:
      - CreateNamespace=true
```

save하면 앱이 만들어지고 sync를 누르면 설치가 된다.

커맨드로 실행하려면 yml을 파일로 저장하고 다음 커맨드를 실행하자.

```bash
kubectl apply -f add-app/cert-manager.yml
```

### repo / app 추가

- argo용 ssh key 생성

  ```bash
  ssh-keygen
  > .ssh/argocd
  ```

  ![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-17-31.png)

- repo 등록
  private/public 키 argocd에 repo에 등록한다. 또는 커맨드로 추가 가능

  ![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-18-57.png)

  ![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-10-19-28.png)

  ```bash
  argocd repo add git@github.com:YOUR/argocd.git --ssh-private-key-path ~/.ssh/argocd
  ```

## nginx 앱 추가

nginx앱을 하나 만들어서 배포해보자.

argocd git에 폴더를 하나 만들자

```bash
mkdir my-webserver
vi service.yml
```

```yml
---
apiVersion: v1
kind: Service
metadata:
  name: www
  namespace: www
  labels:
    app: www
spec:
  selector:
    app: www
  ports:
    - name: http
      port: 80
      targetPort: 80
```

vi deploy.yml

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: www
  namespace: www
  labels:
    app: www
spec:
  replicas: 1
  selector:
    matchLabels:
      app: www
  template:
    metadata:
      labels:
        app: www
    spec:
      containers:
        - name: www
          image: nginx:latest
          ports:
            - containerPort: 80
```

이제 커밋을 하고 argocd 화면에서 app을 추가해 주면 된다.

이제 nginx가 쿠버네티스에 디플로이된것을 화면으로 확인할수 있다.

## aws alb controller (application load balance controller)

쿠버네티스를 직접 설치하고 사용할때는 ingress-nginx를 사용하였으나 eks에는 aws (alb) application load balance를 사용할수 있는 방법이 있다.

처음 고민이 aws에서 로드발란스를 세팅하는게 번거롭다는 고민이 있엇는데 그걸 aws에서 알고 있엇는지 kubernete 설정파일에 적어만 주면 자동으로 alb가 생성이 된다.

<https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html>

이 링크에 있는 내용을 해주면 된다. 간단하게 요약해보면

### Oidc를 이용하여 인증을 체크

oidc.issuer가 있는지 체크

```bash
aws eks describe-cluster --name cluster01 --query "cluster.identity.oidc.issuer" --output text
```

```txt
> https://oidc.eks.us-west-2.amazonaws.com/id/55078434365FAxxx21D4C440DD
```

결과 나왓으므로 이걸로 다시

```bash
aws iam list-open-id-connect-providers | grep 55078434365FAxxx21D4C440DD
```

아무것도 안나온다. 없다는거다 그러면 생성 해줘야 한다. 있으면 생성부분을 넘어가면 된다.

- 없으면 생성 Create IAM OIDC provider

<https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html>

```bash
eksctl utils associate-iam-oidc-provider \
    --region us-west-2 \
    --cluster cluster01 \
    --approve

> 2021-05-04 19:17:23 [ℹ]  eksctl version 0.45.0
> 2021-05-04 19:17:23 [ℹ]  using region us-west-2
> 2021-05-04 19:17:23 [ℹ]  IAM Open ID Connect provider is already associated with cluster "ekc-ekc-cluster-1" in "us-west-2"
```

내용 확인

```bash
aws iam list-open-id-connect-providers | grep 55078434365FAxxx21D4C440DD
```

```bash
> - Arn: arn:aws:iam::849053568:oidc-provider/oidc.eks.us-west-2.amazonaws.com/id/55078434365FAxxx21D4C440DD
```

내용이 나왓으므로 oidc는 만들어졌다.

### Download IAM policy for the AWS Load Balancer Controller

```bash
curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.1.3/docs/install/iam_policy.json
```

### Create an IAM policy called AWSLoadBalancerControllerIAMPolicy

```bash
aws iam create-policy \
 --policy-name AWSLoadBalancerControllerIAMPolicy \
 --policy-document file://iam_policy.json
```

```yml
Policy:
  Arn: arn:aws:iam::849053568:policy/AWSLoadBalancerControllerIAMPolicy
  AttachmentCount: 0
  CreateDate: '2021-05-10T23:28:33+00:00'
  DefaultVersionId: v1
  IsAttachable: true
  Path: /
  PermissionsBoundaryUsageCount: 0
  PolicyId: ANPA4LL7IJKQEH5RKWDGU
  PolicyName: AWSLoadBalancerControllerIAMPolicy
  UpdateDate: '2021-05-10T23:28:33+00:00'
```

### create iam role and annotate kubernetes account named aws-load-balancer-controller in kube-system namespaces

이건 잘 안되는듯 그냥 웹에서 하는게 좋을듯 싶다.

```bash
eksctl create iamserviceaccount \
  --cluster=cluster01 \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --attach-policy-arn=arn:aws:iam::849053568:policy/AWSLoadBalancerControllerIAMPolicy \
  --override-existing-serviceaccounts \
  --approve
```

![]({{ site_baseurl }}/assets/2021-05-25-eks/2021-05-25-09-53-55.png)

이 탭을 눌러서 여기에 적힌대로 진행한다.

웹에서 마지막단계에서 arn을 복사해두자.

```txt
arn:aws:iam::4444444:role/AmazonEKSLoadBalancerControllerRole
```

https://github.com/kubernetes-sigs/aws-load-balancer-controller 에서 최신 릴리즈를 확인하고

git에서 폴더를 하나 만들고

mkdir aws-alb-controller

파일을 다운받는다.

curl -o v2_2_0_full.yaml https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.2.0/docs/install/v2_2_0_full.yaml

파일을 수정하자. clustername만 바꿔주면된다.

파일 추가

vi aws-load-balancer-controller-service-account.yaml

```yml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: aws-load-balancer-controller
  name: aws-load-balancer-controller
  namespace: kube-system
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::xxxxx:role/AmazonEKSLoadBalancerControllerRole
```

arn을 복사해둔 내용을 여기에 적어넣는다.

aws-load-balancer-controller-service-account.yaml 도 위에서 복사해둔 내용을 추가해서 저장

커밋/푸시 하고 앱을 추가하면 쿠버네티스에 적용이 된다.

## nginx app을 alb에 오픈해 보자

## eksctl 기타 사용법

```bash
eksctl get nodegroup --cluster=cluster-1
# 노드 확장
eksctl scale nodegroup --cluster=cluster-1  --nodes=2 --name=c1-nodes
eksctl scale nodegroup --cluster=cluster-1  --nodes=3 --nodes-max=3 --name=c1-nodes

# eksctl scale nodegroup --cluster=<clusterName> --nodes=<desiredCount> --name=<nodegroupName> [ --nodes-min=<minSize> ] [ --nodes-max=<maxSize> ]
```

## delete eks

```bash
eksctl delete cluster --name cluster-1 --wait
```
